{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-Manipulate_data_with_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caroheymes/09-04-DB-SCAN/blob/main/01_Manipulate_data_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNW5K_m7t8Tu"
      },
      "source": [
        "# Manipulate data with tensorflow\n",
        "\n",
        "In this exercise you will practice manipulating tensors and forming tensor datasets with tensorflow.\n",
        "We are taking advantage of this moment to let you only manipulate data as we will be focusing much more on building models in the following days!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scH5vLxifyd0",
        "outputId": "56b60ae7-9d63-4de3-aabc-35344f63d6e8"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds_0PIzNgkF-"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/manipulate_data_with_tf')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awl5S3siIE2I"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be1UHQRtufib"
      },
      "source": [
        "## Practice tensor operations\n",
        "\n",
        "* Create a constant tensor named `tensor1` containing the values `[0,1,2,3,4,5,6,7]` and a variable tensor named `tensor2` containing the values `[0,1,2,0,1,2]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnmEw6ARg-Qt",
        "outputId": "264ad12b-83f3-454a-f4b5-78df1309fb09"
      },
      "source": [
        "tensor1 = tf.constant([0,1,2,3,4,5,6,7])\n",
        "tensor2 = tf.Variable([0,1,2,0,1,2])\n",
        "print(tensor1,'\\n', tensor2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6 7], shape=(8,), dtype=int32) \n",
            " <tf.Variable 'Variable:0' shape=(6,) dtype=int32, numpy=array([0, 1, 2, 0, 1, 2], dtype=int32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kZZuF9FIRPp"
      },
      "source": [
        "* Reshape `tensor1` so it has 2 columns and 4 rows, and `tensor2` so it has 2 rows and 3 columns.\n",
        "Has this operation changed the nature of `tensor2`? How could you change it back to its former nature?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS_WqjF6helD"
      },
      "source": [
        "tensor1 = tf.reshape(tensor1, [4,2])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn9uBG-UipLz",
        "outputId": "830a4e3c-38cd-4dbd-b215-6db1656c77fb"
      },
      "source": [
        "tensor1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\n",
              "array([[0, 1],\n",
              "       [2, 3],\n",
              "       [4, 5],\n",
              "       [6, 7]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYxc2pv-ht0j"
      },
      "source": [
        "tensor2 = tf.reshape(tensor2, [2,3])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM5T5YDFKPKy"
      },
      "source": [
        "tensor2 = tf.Variable(tensor2) #sinon passe en constant à cause du reshape"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9t1o_2FI8gM"
      },
      "source": [
        "* Use a tensorflow function to create `tensor3` with the same shape as `tensor2` but filled with 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD5IKEDGiOm_",
        "outputId": "12394ece-c1e4-4cdb-e5c4-d2a6ab9b4272"
      },
      "source": [
        "import numpy as np\n",
        "tensor3 = tf.Variable(np.ones([2,3]).astype('int32')) #Ou aussi tensor3 = tf.ones_like(tensor2)\n",
        "tensor3"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
              "array([[1, 1, 1],\n",
              "       [1, 1, 1]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-cHLAq6JYB8"
      },
      "source": [
        "* Modify the value of `tensor2` by substracting the values in `tensor3`, use a method so that it is an in place operation. Why would not you be able to do that with `tensor1`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRCjG3E8E9Dq"
      },
      "source": [
        "tensor2 = tensor2.assign_sub(tensor3)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbNEIoLNRIyA",
        "outputId": "7a07cd33-d99f-4192-80d7-e36ac3dfd884"
      },
      "source": [
        "tensor2"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=int32, numpy=\n",
              "array([[-2, -1,  0],\n",
              "       [-2, -1,  0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0CzXqjyKqpF"
      },
      "source": [
        "* Can you multiply `tensor1` and `tensor2` pointwise? How about with a matrix multiplication? Display the result of the possible operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEoqnix5j9o2",
        "outputId": "450da574-99c9-44b3-d8e9-debfa0c6a6af"
      },
      "source": [
        "tensor1.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgzj_E3Yj5vF",
        "outputId": "a6cd6b60-cd9f-4b28-ec10-4ce9727d1c78"
      },
      "source": [
        "tensor2.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBDmBeOIKlw1",
        "outputId": "8224ab24-c4d8-4fdb-df20-7ef44e7caf18"
      },
      "source": [
        "# Pointwise multiplication by a tensor of same shape\n",
        "# print(tensor1 * tensor2)\n",
        "# #impossable car shapes différentes\n",
        "#Produit matriciel possible (broadcasting)\n",
        "tf.matmul(tensor1, tensor2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
              "array([[ -2,  -1,   0],\n",
              "       [-10,  -5,   0],\n",
              "       [-18,  -9,   0],\n",
              "       [-26, -13,   0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Flhy7uLS7w"
      },
      "source": [
        "## Tabular data\n",
        "\n",
        "This part of the exercise will let you deal with tabular data in order to make batch datasets ready to be fed to deep learning models.\n",
        "\n",
        "* Using the `sklearn.datasets` module, load the mnist dataset thanks to the `load_digits` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO54ZELkMDnI"
      },
      "source": [
        "* This function gives you a Data Bunch object, which works basically like a dictionnary. Create an object data containing the value of the `data` key and an object target containing the value of the `target` key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqjkeVCukgy9"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "data = digits.data\n",
        "target = digits.target"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoyvPr2sNGxt"
      },
      "source": [
        "* What is the shape of `data` and `target`? Can you understand what these objects represent using the `DESCR` key of the Data Bunch?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3VytM5ALuCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243f2b04-d25b-42b4-cefd-ece418850449"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKK8rqNFmdP9",
        "outputId": "c90df46f-d9a5-4eff-df3d-50ca25396258"
      },
      "source": [
        "target.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdYSIErjmiDl",
        "outputId": "e40ebe04-4c13-4cff-b176-41945b482323"
      },
      "source": [
        "print(digits.DESCR)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 5620\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "    Graduate Studies in Science and Engineering, Bogazici University.\n",
            "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "    Electrical and Electronic Engineering Nanyang Technological University.\n",
            "    2005.\n",
            "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "    Algorithm. NIPS. 2000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgrbbCLSORpb"
      },
      "source": [
        "* Can you visualize the first image in data ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Ts0WIXUGniL8",
        "outputId": "61964cfc-03d4-4c5e-9fa1-03cf332897db"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Display the first digit\n",
        "plt.figure(1, figsize=(3, 3))\n",
        "plt.imshow(digits.images[0],cmap=plt.cm.gray_r)\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3TwGhRPacK0"
      },
      "source": [
        "* The pixel values from those images is encoded in integers between 0 and 255, it is always better to feed your deep learning models with reasonnably scaled data to avoid the network not being able to learn. To do this we'll divide the value in each pixel by 255. Do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Inf0zR8oIv0"
      },
      "source": [
        "data = data/255"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zazDEYPiaak8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f2cbb58-994e-408d-db1d-fddf9cdd2cce"
      },
      "source": [
        "from collections import Counter\n",
        "Counter(target)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 178,\n",
              "         1: 182,\n",
              "         2: 177,\n",
              "         3: 183,\n",
              "         4: 181,\n",
              "         5: 182,\n",
              "         6: 181,\n",
              "         7: 179,\n",
              "         8: 174,\n",
              "         9: 180})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPVqElsAXHTt"
      },
      "source": [
        "### Technique 1: Split the data with sklearn\n",
        "\n",
        "Most of the time when you will be dealing with data you want to feed to a deap learning model, you will have a pandas DataFrame or numpy array at some points that contains some representation of your data and the associated values of the target variable. In those cases, it's easier to just split the data in a train and validation set using sklearn. (Remember that for very large datasets or for training and evaluating deep learning models we most of the time use the three way hold out method, where on set serves as the training set, one as the validation set to control for overfitting, and the last one is the test set against which we will evaluate the model).\n",
        "\n",
        "* Split the data and target into three different parts, one containing the train set (60%), another with the validation set (20%), and a third with the test set (20%), using sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmVavTzCot3S"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
        "\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size = 0.5)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4bjBVi03Ory",
        "outputId": "890b00a6-ec5f-49f7-ca20-12e3e2ff5638"
      },
      "source": [
        "X_val.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(359, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzugIQTQZOUn"
      },
      "source": [
        "* Form three tensor slice datasets using the training validation and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W96B4A9Mo3yA"
      },
      "source": [
        "train = tf.data.Dataset.from_tensor_slices((X_train,Y_train))\n",
        "test = tf.data.Dataset.from_tensor_slices((X_test,Y_test))\n",
        "val =  tf.data.Dataset.from_tensor_slices((X_val,Y_val))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ft2lVP5ZraP"
      },
      "source": [
        "* Shuffle these tensor slice datasets and arrange them in batches of 8 observations, then display one batch from each of these batch datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUg_TQ6p4d0k"
      },
      "source": [
        "train_shuffle = train.shuffle(buffer_size=len(X_train)) \n",
        "test_shuffle = test.shuffle(buffer_size=len(X_test))\n",
        "val_shuffle = val.shuffle(buffer_size=len(X_val))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEaYmiL15ILi",
        "outputId": "b9d9e29a-9a18-4dbb-ec45-66927ded41a4"
      },
      "source": [
        "train_batch = train_shuffle.batch(batch_size=8)\n",
        "test_batch = test_shuffle.batch(batch_size=8)\n",
        "\n",
        "# When extracting data from these objects we now get batches!\n",
        "for x, y in train_batch.take(1): \n",
        "  print('x:',x)\n",
        "  print('y:',y)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tf.Tensor(\n",
            "[[0.         0.00784314 0.03921569 0.0627451  0.04705882 0.\n",
            "  0.         0.         0.         0.04705882 0.05490196 0.04705882\n",
            "  0.0627451  0.01960784 0.         0.         0.         0.00784314\n",
            "  0.         0.01568627 0.0627451  0.02745098 0.00392157 0.\n",
            "  0.         0.         0.01568627 0.05882353 0.0627451  0.0627451\n",
            "  0.03921569 0.         0.         0.00392157 0.0627451  0.0627451\n",
            "  0.04705882 0.01960784 0.00784314 0.         0.         0.\n",
            "  0.05882353 0.04705882 0.00392157 0.         0.         0.\n",
            "  0.         0.00392157 0.05490196 0.01568627 0.         0.\n",
            "  0.         0.         0.         0.         0.0627451  0.01176471\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.03137255 0.0627451  0.02352941 0.01176471\n",
            "  0.         0.         0.         0.00784314 0.05098039 0.01960784\n",
            "  0.03921569 0.05490196 0.         0.         0.         0.01568627\n",
            "  0.05490196 0.00392157 0.03529412 0.0627451  0.         0.\n",
            "  0.         0.         0.04705882 0.05098039 0.03137255 0.05098039\n",
            "  0.         0.         0.         0.         0.         0.01176471\n",
            "  0.         0.04313725 0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.04705882 0.00784314 0.\n",
            "  0.         0.         0.01568627 0.00392157 0.         0.05490196\n",
            "  0.00392157 0.         0.         0.         0.02352941 0.05882353\n",
            "  0.0627451  0.03921569 0.         0.        ]\n",
            " [0.         0.         0.         0.00392157 0.0627451  0.04313725\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.0627451  0.0627451  0.01568627 0.         0.         0.\n",
            "  0.         0.03137255 0.0627451  0.0627451  0.         0.\n",
            "  0.         0.         0.03921569 0.0627451  0.0627451  0.0627451\n",
            "  0.00392157 0.         0.         0.02352941 0.0627451  0.05490196\n",
            "  0.0627451  0.05882353 0.         0.         0.         0.00392157\n",
            "  0.01176471 0.01960784 0.0627451  0.04705882 0.         0.\n",
            "  0.         0.         0.         0.01568627 0.0627451  0.04705882\n",
            "  0.         0.         0.         0.         0.         0.00784314\n",
            "  0.05882353 0.04705882 0.         0.        ]\n",
            " [0.         0.00392157 0.04705882 0.04705882 0.05098039 0.03137255\n",
            "  0.00392157 0.         0.         0.         0.03137255 0.03529412\n",
            "  0.05882353 0.0627451  0.00784314 0.         0.         0.\n",
            "  0.         0.01176471 0.0627451  0.03921569 0.         0.\n",
            "  0.         0.         0.         0.02745098 0.0627451  0.02352941\n",
            "  0.         0.         0.         0.         0.         0.01960784\n",
            "  0.0627451  0.03921569 0.         0.         0.         0.\n",
            "  0.         0.         0.02745098 0.0627451  0.02745098 0.\n",
            "  0.         0.         0.01176471 0.03137255 0.05882353 0.05098039\n",
            "  0.00784314 0.         0.         0.00784314 0.05490196 0.0627451\n",
            "  0.03921569 0.00392157 0.         0.        ]\n",
            " [0.         0.         0.03529412 0.04705882 0.05490196 0.02352941\n",
            "  0.         0.         0.         0.         0.0627451  0.02352941\n",
            "  0.         0.         0.         0.         0.         0.00784314\n",
            "  0.05882353 0.         0.         0.         0.         0.\n",
            "  0.         0.03137255 0.05882353 0.04705882 0.0627451  0.03529412\n",
            "  0.00392157 0.         0.         0.00392157 0.03137255 0.02352941\n",
            "  0.00784314 0.04705882 0.02745098 0.         0.         0.\n",
            "  0.         0.         0.         0.04313725 0.02745098 0.\n",
            "  0.         0.         0.         0.         0.03137255 0.05882353\n",
            "  0.00784314 0.         0.         0.         0.04705882 0.05490196\n",
            "  0.03529412 0.00784314 0.         0.        ]\n",
            " [0.         0.         0.02352941 0.03921569 0.03137255 0.01176471\n",
            "  0.         0.         0.         0.         0.02352941 0.0627451\n",
            "  0.0627451  0.03529412 0.         0.         0.         0.\n",
            "  0.03529412 0.0627451  0.0627451  0.02352941 0.         0.\n",
            "  0.         0.         0.02745098 0.0627451  0.0627451  0.03921569\n",
            "  0.         0.         0.         0.         0.04313725 0.0627451\n",
            "  0.0627451  0.03137255 0.         0.         0.         0.\n",
            "  0.02745098 0.0627451  0.0627451  0.03529412 0.         0.\n",
            "  0.         0.         0.03921569 0.0627451  0.0627451  0.02352941\n",
            "  0.         0.         0.         0.         0.01568627 0.03529412\n",
            "  0.04705882 0.04313725 0.00784314 0.        ]\n",
            " [0.         0.         0.         0.04313725 0.01568627 0.\n",
            "  0.         0.         0.         0.         0.00392157 0.0627451\n",
            "  0.01568627 0.01176471 0.         0.         0.         0.\n",
            "  0.03921569 0.03529412 0.0627451  0.01568627 0.         0.\n",
            "  0.         0.00784314 0.05490196 0.01960784 0.0627451  0.00784314\n",
            "  0.         0.         0.         0.03137255 0.05098039 0.02745098\n",
            "  0.0627451  0.04313725 0.00784314 0.         0.         0.03921569\n",
            "  0.0627451  0.0627451  0.0627451  0.05490196 0.00392157 0.\n",
            "  0.         0.         0.         0.04313725 0.05098039 0.\n",
            "  0.         0.         0.         0.         0.         0.04313725\n",
            "  0.02745098 0.         0.         0.        ]\n",
            " [0.         0.         0.03921569 0.05098039 0.         0.\n",
            "  0.         0.         0.         0.         0.05490196 0.05882353\n",
            "  0.04313725 0.         0.         0.         0.         0.\n",
            "  0.04705882 0.03529412 0.0627451  0.03137255 0.00784314 0.\n",
            "  0.         0.         0.01960784 0.05490196 0.0627451  0.04313725\n",
            "  0.00392157 0.         0.         0.         0.01176471 0.0627451\n",
            "  0.03921569 0.         0.         0.         0.         0.\n",
            "  0.04705882 0.04313725 0.0627451  0.         0.         0.\n",
            "  0.         0.00392157 0.0627451  0.02745098 0.0627451  0.01960784\n",
            "  0.         0.         0.         0.         0.04313725 0.0627451\n",
            "  0.05098039 0.00392157 0.         0.        ]], shape=(8, 64), dtype=float64)\n",
            "y: tf.Tensor([7 9 1 3 5 1 4 8], shape=(8,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIG8SZ_fbAM4"
      },
      "source": [
        "We are now ready to start training deep learning models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhAb3OHwbFHh"
      },
      "source": [
        "## Technique 2: split using tensorflow\n",
        "\n",
        "This technique is not so recommended because tensorflow is not able to work with datasets in the same way that sklearn does, it is not as practical to split the data in a random way, but we will show you how it can be done, as sometimes you will strictly be working with tensorflow objects.\n",
        "\n",
        "* Create a tensor slice dataset object using `data`and `target`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHxKi-0P7lmD",
        "outputId": "21354c43-e8aa-4deb-aa87-f6100d7122b6"
      },
      "source": [
        "full_ds = tf.data.Dataset.from_tensor_slices((data,target))\n",
        "print(\"full_ds:\", full_ds)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full_ds: <TensorSliceDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLDSGNPIbvMn"
      },
      "source": [
        "* Using the commands take and skip, separate the tensor slice dataset into a train object containing 60% of the data, a val object (20%) and a test object (20%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvTEUACTbuSb",
        "outputId": "8d2dfb90-fce6-4289-a6c5-646b8d761e6f"
      },
      "source": [
        "n_train = int(0.6*len(data))\n",
        "print('n_train : ', n_train)\n",
        "n_val = int(0.2*len(data))\n",
        "print('n_val : ', n_val)\n",
        "n_test = len(data) - n_train - n_val\n",
        "print('n_test : ', n_test)\n",
        "\n",
        "train = full_ds.take(n_train)\n",
        "print('train : ', train, len(train))\n",
        "reste = full_ds.skip(n_train)\n",
        "val = reste.take(n_val)\n",
        "print('val : ', val, len(val))\n",
        "test = reste.take(n_test)\n",
        "print('test : ', test, len(test))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_train :  1078\n",
            "n_val :  359\n",
            "n_test :  360\n",
            "train :  <TakeDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)> 1078\n",
            "val :  <TakeDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)> 359\n",
            "test :  <TakeDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)> 360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTdWCH3ic7Dm"
      },
      "source": [
        "* Use methods shuffle and batch in order to create batch datasets with batches of 8 observations for train, val, and test, and show one batch from each of these objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc2L2kHXOYRc",
        "outputId": "ae3d301e-1d87-4c85-a03b-16bfd22126fb"
      },
      "source": [
        "train_batch = train.shuffle(n_train).batch(8)\n",
        "val_batch = val.shuffle(n_val).batch(8)\n",
        "test_batch = test.shuffle(n_test).batch(8)\n",
        "\n",
        "print(\"train batch:\", next(iter(train_batch)))\n",
        "print(\"val batch:\", next(iter(val_batch)))\n",
        "print(\"test batch:\", next(iter(test_batch)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n",
            "array([[0.        , 0.        , 0.01960784, 0.05490196, 0.05882353,\n",
            "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.03137255, 0.0627451 , 0.0627451 , 0.05490196, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.01960784, 0.0627451 ,\n",
            "        0.0627451 , 0.03529412, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.05882353, 0.0627451 , 0.00392157,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
            "        0.0627451 , 0.05098039, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.04313725, 0.05882353, 0.05490196,\n",
            "        0.01960784, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.04705882, 0.04705882, 0.03137255, 0.05882353, 0.00392157,\n",
            "        0.        , 0.        , 0.        , 0.01960784, 0.0627451 ,\n",
            "        0.0627451 , 0.0627451 , 0.00784314, 0.        ],\n",
            "       [0.        , 0.        , 0.00784314, 0.05098039, 0.00392157,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.05882353, 0.02352941, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.05882353,\n",
            "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.05098039, 0.0627451 , 0.00392157,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.02352941, 0.05882353, 0.02352941, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.04705882,\n",
            "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.01960784, 0.04705882, 0.05490196, 0.0627451 , 0.03529412,\n",
            "        0.00784314, 0.        , 0.        , 0.00784314, 0.04705882,\n",
            "        0.04705882, 0.04705882, 0.05098039, 0.03137255],\n",
            "       [0.        , 0.        , 0.        , 0.01568627, 0.05882353,\n",
            "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.00392157, 0.0627451 , 0.03529412, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.03529412, 0.05882353,\n",
            "        0.00392157, 0.04313725, 0.03529412, 0.        , 0.        ,\n",
            "        0.01176471, 0.05490196, 0.03137255, 0.        , 0.05490196,\n",
            "        0.03921569, 0.        , 0.        , 0.03921569, 0.0627451 ,\n",
            "        0.04705882, 0.04705882, 0.0627451 , 0.03137255, 0.        ,\n",
            "        0.        , 0.05098039, 0.0627451 , 0.05490196, 0.05882353,\n",
            "        0.0627451 , 0.01960784, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.05882353, 0.05098039, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
            "        0.0627451 , 0.03529412, 0.        , 0.        ],\n",
            "       [0.        , 0.00784314, 0.05490196, 0.0627451 , 0.05490196,\n",
            "        0.01568627, 0.        , 0.        , 0.        , 0.01568627,\n",
            "        0.04313725, 0.01960784, 0.05098039, 0.04705882, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
            "        0.05882353, 0.02745098, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.01568627, 0.0627451 , 0.01568627,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.00392157, 0.05098039, 0.05098039, 0.00392157, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
            "        0.0627451 , 0.01568627, 0.        , 0.        , 0.        ,\n",
            "        0.00392157, 0.01176471, 0.04313725, 0.05882353, 0.00784314,\n",
            "        0.        , 0.        , 0.00392157, 0.04705882, 0.0627451 ,\n",
            "        0.03529412, 0.00784314, 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.01176471, 0.03529412, 0.05490196,\n",
            "        0.02745098, 0.        , 0.        , 0.        , 0.01176471,\n",
            "        0.05882353, 0.04313725, 0.03137255, 0.05882353, 0.00784314,\n",
            "        0.        , 0.        , 0.01568627, 0.0627451 , 0.01960784,\n",
            "        0.00784314, 0.0627451 , 0.02745098, 0.        , 0.        ,\n",
            "        0.        , 0.01568627, 0.05882353, 0.05098039, 0.0627451 ,\n",
            "        0.02745098, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.02352941, 0.0627451 , 0.0627451 , 0.00392157, 0.        ,\n",
            "        0.        , 0.        , 0.00784314, 0.05882353, 0.03137255,\n",
            "        0.0627451 , 0.02745098, 0.        , 0.        , 0.        ,\n",
            "        0.01568627, 0.0627451 , 0.01568627, 0.05882353, 0.02745098,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.03921569,\n",
            "        0.05882353, 0.03921569, 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.        , 0.        , 0.03137255,\n",
            "        0.05882353, 0.03529412, 0.        , 0.        , 0.        ,\n",
            "        0.00392157, 0.04705882, 0.03137255, 0.00784314, 0.04313725,\n",
            "        0.        , 0.        , 0.        , 0.03921569, 0.04313725,\n",
            "        0.        , 0.04313725, 0.03137255, 0.        , 0.        ,\n",
            "        0.01960784, 0.0627451 , 0.05490196, 0.05882353, 0.05882353,\n",
            "        0.01176471, 0.        , 0.        , 0.00784314, 0.04705882,\n",
            "        0.03921569, 0.01568627, 0.05490196, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.02352941,\n",
            "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.03529412, 0.02352941, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.03529412, 0.02352941, 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.02745098, 0.05882353, 0.0627451 ,\n",
            "        0.04705882, 0.        , 0.        , 0.        , 0.01568627,\n",
            "        0.0627451 , 0.04313725, 0.04705882, 0.04705882, 0.        ,\n",
            "        0.        , 0.        , 0.00784314, 0.02745098, 0.00392157,\n",
            "        0.05098039, 0.04313725, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.05098039, 0.0627451 , 0.02352941,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.04313725, 0.05882353, 0.0627451 , 0.01176471, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
            "        0.05882353, 0.03137255, 0.        , 0.        , 0.        ,\n",
            "        0.01960784, 0.0627451 , 0.04705882, 0.05882353, 0.03137255,\n",
            "        0.        , 0.        , 0.        , 0.02745098, 0.0627451 ,\n",
            "        0.0627451 , 0.05098039, 0.00784314, 0.        ],\n",
            "       [0.        , 0.        , 0.        , 0.01960784, 0.05882353,\n",
            "        0.05098039, 0.00784314, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.04705882, 0.02745098, 0.04313725, 0.02352941,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.03529412,\n",
            "        0.04705882, 0.05882353, 0.00392157, 0.        , 0.        ,\n",
            "        0.        , 0.00392157, 0.03137255, 0.0627451 , 0.01568627,\n",
            "        0.        , 0.        , 0.        , 0.01176471, 0.05882353,\n",
            "        0.03137255, 0.05098039, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.02745098, 0.04705882, 0.        , 0.03921569,\n",
            "        0.02745098, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.04705882, 0.04313725, 0.03921569, 0.03137255, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.02352941,\n",
            "        0.05098039, 0.03921569, 0.        , 0.        ]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([8, 1, 4, 3, 8, 9, 3, 8])>)\n",
            "val batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n",
            "array([[0.        , 0.        , 0.01960784, 0.05098039, 0.0627451 ,\n",
            "        0.05490196, 0.        , 0.        , 0.        , 0.00392157,\n",
            "        0.05490196, 0.03137255, 0.01960784, 0.0627451 , 0.00784314,\n",
            "        0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
            "        0.00784314, 0.05882353, 0.00784314, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.00784314, 0.03137255, 0.05882353,\n",
            "        0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.05882353, 0.0627451 , 0.05098039, 0.03137255, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.02352941, 0.05490196,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.05098039, 0.02745098, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.02745098, 0.05490196,\n",
            "        0.        , 0.        , 0.        , 0.        ],\n",
            "       [0.        , 0.00392157, 0.05098039, 0.0627451 , 0.03529412,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.03137255,\n",
            "        0.05882353, 0.03137255, 0.05882353, 0.01960784, 0.        ,\n",
            "        0.        , 0.        , 0.04313725, 0.03529412, 0.        ,\n",
            "        0.04705882, 0.03137255, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.04313725, 0.03137255,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.00784314, 0.0627451 , 0.01176471, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.02352941, 0.05882353,\n",
            "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.02745098, 0.0627451 , 0.0627451 , 0.0627451 , 0.03921569,\n",
            "        0.00392157, 0.        , 0.00392157, 0.0627451 , 0.05490196,\n",
            "        0.03921569, 0.03137255, 0.04313725, 0.00392157],\n",
            "       [0.        , 0.        , 0.01176471, 0.04705882, 0.04705882,\n",
            "        0.00392157, 0.        , 0.        , 0.        , 0.01176471,\n",
            "        0.05098039, 0.02352941, 0.03529412, 0.04705882, 0.        ,\n",
            "        0.        , 0.        , 0.03529412, 0.01960784, 0.        ,\n",
            "        0.00784314, 0.05882353, 0.        , 0.        , 0.        ,\n",
            "        0.02745098, 0.03529412, 0.01568627, 0.04705882, 0.0627451 ,\n",
            "        0.00392157, 0.        , 0.        , 0.        , 0.03529412,\n",
            "        0.04313725, 0.01176471, 0.03921569, 0.00784314, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.04313725, 0.01176471, 0.        , 0.        , 0.        ,\n",
            "        0.03921569, 0.00784314, 0.00392157, 0.05098039, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.01176471, 0.05098039,\n",
            "        0.0627451 , 0.01568627, 0.        , 0.        ],\n",
            "       [0.        , 0.00392157, 0.05490196, 0.0627451 , 0.05882353,\n",
            "        0.01568627, 0.        , 0.        , 0.        , 0.01568627,\n",
            "        0.0627451 , 0.03529412, 0.04313725, 0.05882353, 0.01176471,\n",
            "        0.        , 0.        , 0.02352941, 0.0627451 , 0.00392157,\n",
            "        0.03137255, 0.0627451 , 0.00784314, 0.        , 0.        ,\n",
            "        0.00784314, 0.05490196, 0.03921569, 0.05882353, 0.0627451 ,\n",
            "        0.02352941, 0.        , 0.        , 0.        , 0.01176471,\n",
            "        0.04313725, 0.03137255, 0.05882353, 0.01960784, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
            "        0.0627451 , 0.01960784, 0.        , 0.        , 0.        ,\n",
            "        0.01176471, 0.01176471, 0.04313725, 0.05882353, 0.00392157,\n",
            "        0.        , 0.        , 0.        , 0.05098039, 0.0627451 ,\n",
            "        0.05490196, 0.01568627, 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.01960784, 0.04705882, 0.05098039,\n",
            "        0.04705882, 0.        , 0.        , 0.        , 0.02745098,\n",
            "        0.05098039, 0.01960784, 0.03137255, 0.05882353, 0.        ,\n",
            "        0.        , 0.        , 0.01568627, 0.05490196, 0.01568627,\n",
            "        0.05098039, 0.0627451 , 0.01176471, 0.        , 0.        ,\n",
            "        0.        , 0.02352941, 0.04705882, 0.03137255, 0.03529412,\n",
            "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.03137255, 0.03137255, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.02352941, 0.03137255, 0.        , 0.        , 0.        ,\n",
            "        0.00392157, 0.01176471, 0.00784314, 0.05098039, 0.02352941,\n",
            "        0.        , 0.        , 0.        , 0.02352941, 0.0627451 ,\n",
            "        0.0627451 , 0.03137255, 0.00392157, 0.        ],\n",
            "       [0.        , 0.        , 0.        , 0.03137255, 0.04705882,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.01960784, 0.0627451 , 0.01176471, 0.        , 0.00784314,\n",
            "        0.        , 0.        , 0.00392157, 0.0627451 , 0.01960784,\n",
            "        0.00392157, 0.03921569, 0.05882353, 0.00392157, 0.        ,\n",
            "        0.03529412, 0.0627451 , 0.01568627, 0.03529412, 0.0627451 ,\n",
            "        0.02745098, 0.        , 0.        , 0.02745098, 0.0627451 ,\n",
            "        0.0627451 , 0.0627451 , 0.02745098, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.00784314, 0.03137255, 0.0627451 ,\n",
            "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.03921569, 0.05098039, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.04705882,\n",
            "        0.03921569, 0.        , 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.04313725, 0.0627451 , 0.0627451 ,\n",
            "        0.04705882, 0.        , 0.        , 0.        , 0.01176471,\n",
            "        0.0627451 , 0.02745098, 0.05490196, 0.0627451 , 0.00392157,\n",
            "        0.        , 0.        , 0.        , 0.05882353, 0.05490196,\n",
            "        0.05882353, 0.0627451 , 0.02352941, 0.        , 0.        ,\n",
            "        0.        , 0.00784314, 0.03921569, 0.03529412, 0.05882353,\n",
            "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.03529412, 0.03921569, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.04705882, 0.03137255, 0.        , 0.        , 0.        ,\n",
            "        0.02352941, 0.04313725, 0.02352941, 0.05882353, 0.01960784,\n",
            "        0.        , 0.        , 0.        , 0.03529412, 0.0627451 ,\n",
            "        0.0627451 , 0.04705882, 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.00392157, 0.05490196, 0.05490196,\n",
            "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.00392157, 0.05490196, 0.0627451 , 0.01176471, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.03921569,\n",
            "        0.0627451 , 0.00784314, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.04313725, 0.0627451 , 0.01960784,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.05882353, 0.0627451 , 0.01960784, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.05882353, 0.0627451 ,\n",
            "        0.01960784, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.03921569, 0.0627451 , 0.04705882, 0.00392157,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
            "        0.0627451 , 0.04313725, 0.        , 0.        ]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([7, 2, 9, 9, 9, 4, 9, 1])>)\n",
            "test batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n",
            "array([[0.        , 0.        , 0.        , 0.02352941, 0.0627451 ,\n",
            "        0.02352941, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.01176471, 0.0627451 , 0.03529412, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.00392157, 0.05098039, 0.05098039,\n",
            "        0.00392157, 0.00784314, 0.00392157, 0.        , 0.        ,\n",
            "        0.02745098, 0.0627451 , 0.01960784, 0.00392157, 0.05490196,\n",
            "        0.03921569, 0.        , 0.        , 0.04705882, 0.0627451 ,\n",
            "        0.03137255, 0.04705882, 0.0627451 , 0.00784314, 0.        ,\n",
            "        0.        , 0.00784314, 0.04705882, 0.05882353, 0.0627451 ,\n",
            "        0.04313725, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.03137255, 0.0627451 , 0.01568627, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.03137255,\n",
            "        0.05882353, 0.        , 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.        , 0.00392157, 0.05882353,\n",
            "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.03921569, 0.05882353, 0.01176471, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.03529412, 0.0627451 ,\n",
            "        0.01960784, 0.01176471, 0.02352941, 0.        , 0.        ,\n",
            "        0.01960784, 0.0627451 , 0.03137255, 0.        , 0.04705882,\n",
            "        0.05098039, 0.        , 0.        , 0.04705882, 0.05490196,\n",
            "        0.01568627, 0.03137255, 0.0627451 , 0.03529412, 0.        ,\n",
            "        0.        , 0.04705882, 0.0627451 , 0.0627451 , 0.0627451 ,\n",
            "        0.0627451 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.01568627, 0.00784314, 0.05490196, 0.04313725, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
            "        0.0627451 , 0.03529412, 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.        , 0.03137255, 0.04705882,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.01960784, 0.0627451 , 0.01176471, 0.        , 0.00784314,\n",
            "        0.        , 0.        , 0.00392157, 0.0627451 , 0.01960784,\n",
            "        0.00392157, 0.03921569, 0.05882353, 0.00392157, 0.        ,\n",
            "        0.03529412, 0.0627451 , 0.01568627, 0.03529412, 0.0627451 ,\n",
            "        0.02745098, 0.        , 0.        , 0.02745098, 0.0627451 ,\n",
            "        0.0627451 , 0.0627451 , 0.02745098, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.00784314, 0.03137255, 0.0627451 ,\n",
            "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.03921569, 0.05098039, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.04705882,\n",
            "        0.03921569, 0.        , 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.01568627, 0.05882353, 0.04705882,\n",
            "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.03529412, 0.0627451 , 0.05490196, 0.00784314, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.04705882, 0.0627451 ,\n",
            "        0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.04313725, 0.0627451 , 0.04705882, 0.00392157,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.03529412,\n",
            "        0.0627451 , 0.05490196, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.03921569, 0.0627451 , 0.04705882,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.03529412, 0.0627451 , 0.05490196, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.01568627, 0.04705882,\n",
            "        0.04705882, 0.        , 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.00784314, 0.03921569, 0.0627451 ,\n",
            "        0.04705882, 0.        , 0.        , 0.        , 0.00784314,\n",
            "        0.05882353, 0.05490196, 0.03137255, 0.00392157, 0.        ,\n",
            "        0.        , 0.        , 0.00784314, 0.0627451 , 0.01568627,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.02352941, 0.0627451 , 0.05490196, 0.05098039, 0.01176471,\n",
            "        0.        , 0.        , 0.        , 0.03921569, 0.0627451 ,\n",
            "        0.02745098, 0.04313725, 0.04705882, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.00392157, 0.        , 0.01568627,\n",
            "        0.0627451 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.02745098, 0.0627451 , 0.00784314,\n",
            "        0.        , 0.        , 0.        , 0.00784314, 0.05490196,\n",
            "        0.0627451 , 0.03137255, 0.        , 0.        ],\n",
            "       [0.        , 0.01960784, 0.05882353, 0.04705882, 0.04705882,\n",
            "        0.04705882, 0.01568627, 0.        , 0.        , 0.03921569,\n",
            "        0.05490196, 0.04705882, 0.04705882, 0.03529412, 0.02745098,\n",
            "        0.        , 0.        , 0.04705882, 0.04313725, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.01960784, 0.05882353, 0.03921569, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
            "        0.0627451 , 0.01176471, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.05882353, 0.01568627,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
            "        0.02745098, 0.0627451 , 0.01568627, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.01568627, 0.05882353, 0.04705882,\n",
            "        0.        , 0.        , 0.        , 0.        ],\n",
            "       [0.        , 0.        , 0.        , 0.02352941, 0.04705882,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.01960784, 0.0627451 , 0.02745098, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.04705882, 0.03529412,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.00392157, 0.0627451 , 0.01960784, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.00392157, 0.0627451 ,\n",
            "        0.03921569, 0.04705882, 0.03529412, 0.00784314, 0.        ,\n",
            "        0.        , 0.        , 0.05098039, 0.03137255, 0.00784314,\n",
            "        0.01960784, 0.05098039, 0.        , 0.        , 0.        ,\n",
            "        0.02352941, 0.04313725, 0.00392157, 0.00784314, 0.0627451 ,\n",
            "        0.01176471, 0.        , 0.        , 0.        , 0.03137255,\n",
            "        0.04313725, 0.05490196, 0.04313725, 0.00784314],\n",
            "       [0.        , 0.00784314, 0.05882353, 0.05882353, 0.01176471,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.04313725,\n",
            "        0.05882353, 0.04313725, 0.04705882, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.03137255, 0.03921569, 0.        ,\n",
            "        0.0627451 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.00392157, 0.01176471, 0.00784314, 0.0627451 , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.01568627, 0.04705882, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.00392157, 0.04705882, 0.03529412,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.05490196, 0.0627451 , 0.05098039, 0.05098039, 0.05882353,\n",
            "        0.01176471, 0.        , 0.00784314, 0.05098039, 0.05490196,\n",
            "        0.04705882, 0.04705882, 0.03137255, 0.00392157]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([4, 4, 4, 1, 5, 5, 6, 2])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fUS1ootddPP"
      },
      "source": [
        "Congratulations, you know two different ways of forming datasets that are fit for training deep learning models with tensorflow! This skill will come in very handy as we will try to focus more on building models from now on, and put less focus on preprocessing.\n",
        "Until then, happy learning!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEgU351Ss_HP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}